{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hxk271/SocDataSci/blob/main/archive/W07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 오늘의 파이썬\n"
      ],
      "metadata": {
        "id": "CGt7xpvneCnv"
      },
      "id": "CGt7xpvneCnv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 구글 콜랩에서 파일 다운로드하기\n",
        "\n",
        "> 지금까지 우리는 구글 콜랩을 사용해 코딩을 해왔다. 그러므로 위와 같이 다운로드한 파일은 여러분이 지금 사용하고 있는 **단말기(terminal)**, 즉 로컬 컴퓨터에 저장된 것이 아니다. 그것은 구글 드라이브의 임시 클라우드에 저장되어 있다. 여러분이 **런타임(runtime)**을 끊으면 이것들은 곧 청소된다.\n",
        ">\n",
        "> 먼저 연습용 자료 `corn.csv`를 다운로드받자."
      ],
      "metadata": {
        "id": "SMu47eGuLJkR"
      },
      "id": "SMu47eGuLJkR"
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "link = 'https://drive.google.com/uc?id=1-C-X3UVIy4__qAtV-enbEV0spDPQvydV'\n",
        "gdown.download(link)"
      ],
      "metadata": {
        "id": "R5SnNwjpPx02"
      },
      "execution_count": null,
      "outputs": [],
      "id": "R5SnNwjpPx02"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 자 그런데 여러분이 이 파일을 여러분의 로컬에 다운로드받고 싶다면 몇 가지 방법이 있다. 우선 좌측 레이아웃에서 폴더 아이콘을 누르고 마우스 조작을 통해 직접 다운로드받을 수 있다. 그러나 만일 수많은 파일들을 다운로드받는 상황이라면 다운로드 받는 프로세스를 코딩해야 한다(Why?)."
      ],
      "metadata": {
        "id": "nEZV7hpcP0kB"
      },
      "id": "nEZV7hpcP0kB"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('corn.csv')"
      ],
      "metadata": {
        "id": "WQRh9Xi6g5eR"
      },
      "execution_count": null,
      "outputs": [],
      "id": "WQRh9Xi6g5eR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 위의 코드에서 우리는 `from`과 `import`를 함께 사용했다. 이건 라이브러리의 일부분만을 불러오고 싶을 때 사용하며, 사실 아래 코드와 완전히 같은 기능을 수행한다."
      ],
      "metadata": {
        "id": "CctX19_Fh-HD"
      },
      "id": "CctX19_Fh-HD"
    },
    {
      "cell_type": "code",
      "source": [
        "import google.colab.files\n",
        "\n",
        "google.colab.files.download('corn_new.csv')"
      ],
      "metadata": {
        "id": "yiwaoIzbh4qG"
      },
      "execution_count": null,
      "outputs": [],
      "id": "yiwaoIzbh4qG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **연습문제 1**. 구글 콜랩에서 샘플로 제공되는 데이터 중에 `california_housing_test.csv` 파일을 로컬 컴퓨터로 다운로드 받으시오."
      ],
      "metadata": {
        "id": "pOPR3RFwQP9m"
      },
      "id": "pOPR3RFwQP9m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 구글 콜랩과 구글 드라이브 연동하기\n",
        "\n",
        "> 구글 콜랩이라는 개발환경이 여러분의 구글 드라이브와 동떨어져 있으면 사용하기 은근히 불편하다. 이때 괜찮은 대안 중 하나는 구글 드라이브를 아예 구글 콜랩이라는 개발환경과 연동하는 것이다. 이를 위해 구글 드라이브를 <b>마운트(mount)</b>하자.\n",
        ">\n",
        "> 여러분의 화면 좌측 아래를 <b>폴더(folder)</b> 아이콘이 있다. 그걸 클릭했을 때 나오는 파일(File) 아래 세번째 아이콘이 바로 아래 마운트 코드를 자동 생성해준다."
      ],
      "metadata": {
        "id": "el5rFGfwefK3"
      },
      "id": "el5rFGfwefK3"
    },
    {
      "cell_type": "code",
      "source": [
        "#이 셀을 실행하면 마운트한다!\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eWhiE18me005"
      },
      "id": "eWhiE18me005",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 이제 구글 드라이브로부터 직접 파일을 불러올 수 있다! 가령 폴더 아이콘을 눌렀을 때 나오는 파일 목록에서 temp_seoul.csv가 있다면, 아래와 같은 코드를 별도 다운로드 없이 바로 수행할 수 있다(Why?)."
      ],
      "metadata": {
        "id": "--Y-j8sPe53a"
      },
      "id": "--Y-j8sPe53a"
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "file = open('/content/drive/MyDrive/Colab Notebooks/Data/temp_seoul.csv', 'r', encoding = 'cp949')\n",
        "data = csv.reader(file, delimiter = ',')\n",
        "\n",
        "#첫 7줄은 쓸모없음\n",
        "for i in range(0,7):\n",
        "    next(data)\n",
        "\n",
        "#진짜 헤더\n",
        "header = next(data)\n",
        "\n",
        "for row in data:\n",
        "\n",
        "    #탭만 들어있는 관측치\n",
        "    if row == ['\\t']:\n",
        "        break\n",
        "\n",
        "    #만약 결측치라면 -999를 넣을 것!\n",
        "    if row[-1] =='':\n",
        "        row[-1] = -999\n",
        "\n",
        "    #문자열인 최고기온을 실수로 변환\n",
        "    row[-1] = float(row[-1])\n",
        "\n",
        "    #결과 출력\n",
        "    print(row)\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "id": "ecg0Vexde2dh"
      },
      "id": "ecg0Vexde2dh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **연습문제 2**. 여러분이 평소에 구글 드라이브에 있던 csv 파일을 파이썬에서 직접 접근하여 출력하는 코드를 작성하시오."
      ],
      "metadata": {
        "id": "u1TdH0rMhP1Z"
      },
      "id": "u1TdH0rMhP1Z"
    },
    {
      "cell_type": "markdown",
      "id": "299b8bf8",
      "metadata": {
        "id": "299b8bf8"
      },
      "source": [
        "# Week 07 (pandas 입문하기)\n",
        "\n",
        "데이터란 복잡해보여도 결국 많은 숫자의 행렬이다(Why?). 엑셀과 같은 스프레드시트(spreadsheet)가 편리하게 느껴지는 이유는 그 행렬의 구조를 실시간으로 직접 관찰할 수 있기 때문이다. 사실 파이썬에서도 마치 SPSS처럼 편리하게 분석할 수 있는 몇 가지 도구들이 있다.그 대표적인 두 가지 도구가 바로 numpy와 pandas이다. numpy는 수학을 위한 코딩 도구에 가깝고, pandas는 특히 엑셀처럼 데이터 관리에 편리한 도구라고 볼 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c27aa25d",
      "metadata": {
        "id": "c27aa25d"
      },
      "source": [
        "## 3. 데이터프레임\n",
        "\n",
        "> pandas를 사용하면 자료를 **데이터프레임(DataFrame)** 안에 집어넣을 수 있다(줄여서 ``df``라고 부르자). 일단 자료를 데이터프레임으로 전환하면 굉장히 쉽게 많은 것들을 처리할 수 있다. pandas를 `pd`라는 이름으로 `import`하고, `read_csv()` 함수로 자료를 불러오자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2ac38ce",
      "metadata": {
        "scrolled": true,
        "id": "c2ac38ce"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('corn.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " > 예전에 비해 믿을 수 없을만큼 편리하다! 예전엔 어떻게 했는지 비교해보자."
      ],
      "metadata": {
        "id": "NSYvBMTR3RpH"
      },
      "id": "NSYvBMTR3RpH"
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "file = open('/content/corn.csv')\n",
        "data = csv.reader(file)\n",
        "\n",
        "header = next(data)\n",
        "\n",
        "for row in data:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "c4TLksrB3QtP",
        "collapsed": true
      },
      "id": "c4TLksrB3QtP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 불러온 데이터프레임의 구체적인 속성을 변수별로 살펴볼 수도 있다. 몇 가지 중요한 정보, 특히 각 변수의 <b>속성(dtype)</b>과 유효 사례수를 알 수 있다. `object`와 `int`를 구분하는 것이 특히 중요한데, '1'과 \"1\"이 다르기 때문이다."
      ],
      "metadata": {
        "id": "Ltm2utj2gARX"
      },
      "id": "Ltm2utj2gARX"
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Cn8gN3FbfpZe"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Cn8gN3FbfpZe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 데이터가 길면 첫 몇 줄만 살펴보는게 편하다!"
      ],
      "metadata": {
        "id": "paIm8FWxQ0Fk"
      },
      "id": "paIm8FWxQ0Fk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deb22e0e",
      "metadata": {
        "id": "deb22e0e"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbabfff6",
      "metadata": {
        "id": "fbabfff6"
      },
      "source": [
        "> 데이터프레임에서는 <b>인덱스(index)</b>로 행(rows)을, <b>컬럼(column)</b>으로 열(column)을 나타낸다. 이것은 데이터베이스에서 널리 사용되는 용어로 알아두자. 그러므로 `df.index`로 모든 인덱스를 확인할 수 있고, `df.columns`으로 모든 컬럼을 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3356becf",
      "metadata": {
        "scrolled": true,
        "id": "3356becf"
      },
      "outputs": [],
      "source": [
        "df.columns      #헤더 보기\n",
        "df.index        #인덱스 보기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **연습문제 3-1**. `corn.csv`의 자료의 성격을 파악하고자 한다.\n",
        ">\n",
        "> (1) 변수는 모두 몇 개인가? <br>\n",
        "> (2) 관측치는 모두 몇 개인가?"
      ],
      "metadata": {
        "id": "0gpkdIiPi-JU"
      },
      "id": "0gpkdIiPi-JU"
    },
    {
      "cell_type": "code",
      "source": [
        "#변수 갯수\n",
        "print(len(df.columns))\n",
        "\n",
        "#관측치 갯수\n",
        "print(len(df.index))\n",
        "print(len(df))"
      ],
      "metadata": {
        "id": "W44QvoGtjtHS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "W44QvoGtjtHS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 하나의 변수를 확인하고 싶다면 마치 ``dict``를 검색하는 요령으로 ``df``를 사용한다!"
      ],
      "metadata": {
        "id": "BaLOUoRORooS"
      },
      "id": "BaLOUoRORooS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b4aa856",
      "metadata": {
        "scrolled": true,
        "id": "6b4aa856"
      },
      "outputs": [],
      "source": [
        "df['cornhec']       #cornhec 변수만 보기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 여러개의 변수를 살펴보려면 리스트 안의 리스트를 입력한다."
      ],
      "metadata": {
        "id": "6eG43zvmqdtl"
      },
      "id": "6eG43zvmqdtl"
    },
    {
      "cell_type": "code",
      "source": [
        "vars = ['cornhec', 'soyhec']\n",
        "df[vars]\n",
        "\n",
        "#또는\n",
        "df[['cornhec', 'soyhec']]"
      ],
      "metadata": {
        "id": "iscmblsxqhWV"
      },
      "id": "iscmblsxqhWV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 그런데 하나의 데이터프레임(``df``)은 사실 여러 <b>수열(series)</b>의 조합이다. <b>변수(variable)</b>는 수열이고 그러한 수열들이 합쳐져 <b>자료(data)</b>를 구성하고 있음을 떠올리자."
      ],
      "metadata": {
        "id": "jt9XfNVSelkM"
      },
      "id": "jt9XfNVSelkM"
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터프레임(dataframe)\n",
        "print(type(df))\n",
        "\n",
        "#수열(series)\n",
        "print(type(df['cornhec']))"
      ],
      "metadata": {
        "id": "Al-kIGVcejJt"
      },
      "id": "Al-kIGVcejJt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 인덱싱(indexing)과 슬라이싱(slicing)을 활용할 수도 있다."
      ],
      "metadata": {
        "id": "9ZYJJJX3z4ub"
      },
      "id": "9ZYJJJX3z4ub"
    },
    {
      "cell_type": "code",
      "source": [
        "#0에서 9번째 줄까지(10 제외)\n",
        "df[0:10]\n",
        "\n",
        "#integer-location 1\n",
        "df.iloc[0:10]\n",
        "\n",
        "#integer-location 2\n",
        "df.iloc[5]"
      ],
      "metadata": {
        "id": "so8R2L1Yz5Tj"
      },
      "id": "so8R2L1Yz5Tj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **연습문제 3-2**. `corn.csv` 데이터의 뒤에서 다섯 줄을 살펴보시오."
      ],
      "metadata": {
        "id": "BIsLJSTcZxhQ"
      },
      "id": "BIsLJSTcZxhQ"
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "df.tail()\n",
        "\n",
        "#2\n",
        "df[-5:]\n",
        "\n",
        "#3\n",
        "df[32:]"
      ],
      "metadata": {
        "id": "CCqaM-07Zx-v"
      },
      "execution_count": null,
      "outputs": [],
      "id": "CCqaM-07Zx-v"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 데이터를 주의깊게 살펴보기 위해 당연히 관측치(observations)와 변수를 동시에 특정하여 선별할 수도 있다. 보다 구체적으로, 인덱싱(indexing)과 슬라이싱(slicing)을 활용하여 원하는 <b>부분행렬(submatrix)</b>을 가져올 수 있다. 아래 코드를 하나하나 순서대로 연습해보자. 아래 코드를 하나하나 순서대로 연습해보자."
      ],
      "metadata": {
        "id": "vCi4QXtky5UU"
      },
      "id": "vCi4QXtky5UU"
    },
    {
      "cell_type": "code",
      "source": [
        "#하나의 관측치 + 하나의 변수\n",
        "print(df.iloc[5]['cornhec'])\n",
        "\n",
        "#여러 관측치 + 여러 변수\n",
        "print(df.iloc[5:10][['cornhec', 'cornpix']])"
      ],
      "metadata": {
        "id": "ByjWm2uIqIoV"
      },
      "id": "ByjWm2uIqIoV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 수치에 의한 필터링\n",
        "\n",
        "> 일단 ``df``를 만든 뒤에는 논리 조건에 부합하는가 여부를 따지는 이른바 <b>마스킹(masking)</b>을 할 수 있다. 이는 리스트에서 제공하지 않는 유용한 기능이다."
      ],
      "metadata": {
        "id": "TPvqG9LwT8uL"
      },
      "id": "TPvqG9LwT8uL"
    },
    {
      "cell_type": "code",
      "source": [
        "cond = df['cornhec'] > 100\n",
        "cond        #True or False\n",
        "\n",
        "#조건 cond를 df에 적용하기!\n",
        "df[cond]"
      ],
      "metadata": {
        "id": "Hzpug_KJUMv_"
      },
      "id": "Hzpug_KJUMv_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ``~`` (tilde)를 쓰면 그 역(negation)을 적용할 수 있다."
      ],
      "metadata": {
        "id": "5KnH9KVuUm5j"
      },
      "id": "5KnH9KVuUm5j"
    },
    {
      "cell_type": "code",
      "source": [
        "df[~cond]"
      ],
      "metadata": {
        "id": "hbLmE5l8UpdV"
      },
      "id": "hbLmE5l8UpdV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 능수능란하게 원하는 조건을 적용하여 자료를 <b>선별(filter)</b>해 낼 수 있어야 한다. 이때 학기 초에 배웠던 <b>논리 연산자(logical operator)</b>가 중요하게 사용된다!"
      ],
      "metadata": {
        "id": "zCoNsdbC-DKk"
      },
      "id": "zCoNsdbC-DKk"
    },
    {
      "cell_type": "code",
      "source": [
        "cond1 = df['cornhec'] > 100\n",
        "cond2 = df['soyhec'] < 100\n",
        "\n",
        "df[cond1 + cond2]           #둘 중 하나의 조건이라도 참일 경우\n",
        "df[cond1 | cond2]           #둘 중 하나의 조건이라도 참일 경우\n",
        "\n",
        "df[cond1 * cond2]           #두 가지 조건이 모두 참일 경우\n",
        "df[cond1 & cond2]           #두 가지 조건이 모두 참일 경우"
      ],
      "metadata": {
        "id": "nhrOLvKAUuw8"
      },
      "id": "nhrOLvKAUuw8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **연습문제 4-1**. `corn.csv`에서 옥수수 재배 면적이 100 헥타르보다 작지만, 옥수수 위성사진 픽셀(pixel) 수는 250 보다 큰 카운티를 선별하시오."
      ],
      "metadata": {
        "id": "BmIrLDYR-XOB"
      },
      "id": "BmIrLDYR-XOB"
    },
    {
      "cell_type": "code",
      "source": [
        "cond1 = df['cornhec']<100\n",
        "cond2 = df['cornpix']>250\n",
        "df[cond1 & cond2]"
      ],
      "metadata": {
        "id": "pLOGrVq4-ZIc"
      },
      "id": "pLOGrVq4-ZIc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **연습문제 4-2**. `corn.csv`에서 다음 두 가지 조건 중 <b>하나 이상</b> 성립하는 모든 관측치를 필터링하시오.\n",
        ">\n",
        "> (1) 콩 재배 면적이 150 헥타르보다 크고 콩 픽셀이 100보다 크다. \\\n",
        "> (2) 옥수수 재배 면적이 150 헥타르보다 크고 옥수수 픽셀이 100보다 크다."
      ],
      "metadata": {
        "id": "S8oLVYaYIPeE"
      },
      "id": "S8oLVYaYIPeE"
    },
    {
      "cell_type": "code",
      "source": [
        "cond1 = df['soyhec'] > 150\n",
        "cond2 = df['soypix'] > 100\n",
        "cond3 = df['cornhec'] > 150\n",
        "cond4 = df['cornpix'] > 100\n",
        "df[(cond1 & cond2) | (cond3 & cond4)]"
      ],
      "metadata": {
        "id": "WFBlbYnKHxK4"
      },
      "id": "WFBlbYnKHxK4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8217d3e3",
      "metadata": {
        "id": "8217d3e3"
      },
      "source": [
        "## 5. 문자에 의한 필터링\n",
        "\n",
        "> pandas는 몇 가지 문자열에 대해 사용할 수 있는 편리한 기능들을 지원한다. 특히 `str.contains()`가 문자열과 관련하여 유용하다. 아래 코드에서 `df.column`만 입력하면 뭐가 나왔는지 떠올려보자!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf3caf82",
      "metadata": {
        "id": "cf3caf82"
      },
      "outputs": [],
      "source": [
        "df.columns                         #헤더 보기\n",
        "df.columns.str.contains('corn')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 문자열의 <b>완전 일치(complete matching)</b>와 내포를 구별해야 한다."
      ],
      "metadata": {
        "id": "EeU6chCOJ8Ro"
      },
      "id": "EeU6chCOJ8Ro"
    },
    {
      "cell_type": "code",
      "source": [
        "'county' in df.columns     #True\n",
        "'corn' in df.columns       #False. 왜 그럴까?"
      ],
      "metadata": {
        "id": "qTqO7ggwDVYD"
      },
      "id": "qTqO7ggwDVYD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> `in`이라는 <b>연산자(operator)</b>의 작동 원리가 조금 혼동스러울 수 있으므로 다시 한 번 복습해보자."
      ],
      "metadata": {
        "id": "bULIjf0kKFeg"
      },
      "id": "bULIjf0kKFeg"
    },
    {
      "cell_type": "code",
      "source": [
        "'corn' in 'cornfield'              #True\n",
        "'corn' in ['cornfield']            #False\n",
        "'corn' in ['corn', 'cornfield']    #True"
      ],
      "metadata": {
        "id": "kk7djunGKVt5"
      },
      "id": "kk7djunGKVt5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d1275f9d",
      "metadata": {
        "id": "d1275f9d"
      },
      "source": [
        "> **연습문제 5-1**. `corn.csv`에서 `soy`이라는 단어가 들어가지 <b>않은</b> 모든 변수의 목록을 출력하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e654553",
      "metadata": {
        "id": "6e654553"
      },
      "outputs": [],
      "source": [
        "df.columns[~df.columns.str.contains('soy')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab977ecd",
      "metadata": {
        "id": "ab977ecd"
      },
      "source": [
        "> **연습문제 5-2**. `df`를 각각 corn에 관한 것과 soy에 관한 것 둘로 쪼개고자 한다. `df_corn` 데이터프레임은 `corn`에 관한 변수만을, `df_soy` 데이터프레임은 `soy`에 관한 변수만을 각각 갖도록 만드시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94a9fdaf",
      "metadata": {
        "scrolled": true,
        "id": "94a9fdaf"
      },
      "outputs": [],
      "source": [
        "df_corn = df[df.columns[df.columns.str.contains('corn')]]\n",
        "df_soy = df[df.columns[df.columns.str.contains('soy')]]\n",
        "\n",
        "df_corn\n",
        "df_soy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cd79308"
      },
      "source": [
        "## 6. 자료의 정렬\n",
        "\n",
        "> `soypix` 변수의 크기 순서대로 <b>정렬(sort)</b>해보자. 이때 정렬한 내용이 데이터에 저절로 반영되지 않음에 주의해야 한다(Why?)!"
      ],
      "id": "8cd79308"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5f93c7d"
      },
      "outputs": [],
      "source": [
        "#\n",
        "df.sort_values(by = 'soypix')\n",
        "\n",
        "#내림차순\n",
        "df.sort_values(by = 'soypix', ascending = False)\n",
        "\n",
        "#반영하기\n",
        "df_sorted = df.sort_values(by = 'soypix', ascending = False)\n",
        "\n",
        "df            #정렬 안됨\n",
        "df_sorted     #정렬 됨"
      ],
      "id": "a5f93c7d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pMoz5N4qGYm"
      },
      "source": [
        "> 위에서 작업한 내용을 엑셀로 저장하고 여러분의 단말기로 다운로드하자. 이때 ``df``에 대하여 ``to_excel`` 메서드를 사용하면 그 ``df`` 내용을 엑셀 파일로 저장할 수 있다. 아까 ``to_csv`` 매서드를 어떻게 사용했는지 살펴보자."
      ],
      "id": "1pMoz5N4qGYm"
    },
    {
      "cell_type": "code",
      "source": [
        "import google.colab.files\n",
        "\n",
        "df.to_excel('corn.xlsx')               #아까는 to_csv() 였다!\n",
        "google.colab.files.download('corn.xlsx')"
      ],
      "metadata": {
        "id": "VEEm_nUc5dcN"
      },
      "execution_count": null,
      "outputs": [],
      "id": "VEEm_nUc5dcN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> `sort_values()`를 조금 더 연습해보자. 우리는 학기 초에 청주시 기온 공공 데이터를 사용하여 최저기온이 가장 낮았을 때는 언제의 몇 도인가를 살펴보았다. pandas를 사용하여 같은 분석을 수행해보면 어떨까?"
      ],
      "metadata": {
        "id": "ciRdTliUa9JI"
      },
      "id": "ciRdTliUa9JI"
    },
    {
      "cell_type": "code",
      "source": [
        "#이 자료의 구글 드라이브 링크는 다음과 같다.\n",
        "import gdown\n",
        "link = 'https://drive.google.com/uc?id=1hEwis-Wke7sQFbgmzeFjyWDMbkwN2Ar-'\n",
        "gdown.download(link)"
      ],
      "metadata": {
        "id": "I8t8KZeabI4N"
      },
      "execution_count": null,
      "outputs": [],
      "id": "I8t8KZeabI4N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 이 자료의 8번째 관측치에서 겨우 변수명이 온다. 그러므로!"
      ],
      "metadata": {
        "id": "Ftps1tbu4BFc"
      },
      "id": "Ftps1tbu4BFc"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('temp_chungju.csv', encoding = 'cp949', skiprows=7)     #skip rows\n",
        "df"
      ],
      "metadata": {
        "id": "bGehtyapbQoD"
      },
      "execution_count": null,
      "outputs": [],
      "id": "bGehtyapbQoD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 자료의 맨 마지막 줄은 쓸떼없이 탭(`\\t`)이 들어가 있었던 것을 떠올리자."
      ],
      "metadata": {
        "id": "aknJfUhi-Jlg"
      },
      "id": "aknJfUhi-Jlg"
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[-1]        #자동적으로 제거해주었다!"
      ],
      "metadata": {
        "id": "ALdHb30T-KfH"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ALdHb30T-KfH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 그동안 배운 내용을 토대로 역대 가장 낮은 최저기온을 알아내는 알고리즘을 구현하려면 상당히 어려웠다. 좀 더 쉬운 방법은 없을까? 물론 있다."
      ],
      "metadata": {
        "id": "1Z9qpXlD-awu"
      },
      "id": "1Z9qpXlD-awu"
    },
    {
      "cell_type": "code",
      "source": [
        "lowest = df.sort_values(by = '최저기온(℃)', ascending = True)\n",
        "lowest.iloc[0][['날짜','최저기온(℃)']]"
      ],
      "metadata": {
        "id": "4uvZa3UC-3RP"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4uvZa3UC-3RP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 결과물을 아래 코드와 비교해보자."
      ],
      "metadata": {
        "id": "ChusjY6U-fLf"
      },
      "id": "ChusjY6U-fLf"
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "min_temp = 999      # 최저 기온값이 기록될 placeholder\n",
        "min_date = ''       # 그 날이 언제인지 기록될 placeholder\n",
        "\n",
        "file = open('temp_chungju.csv', 'r', encoding = 'cp949')\n",
        "data = csv.reader(file, delimiter = ',')\n",
        "\n",
        "#첫 7줄은 쓸모없음\n",
        "for i in range(0,7):\n",
        "    next(data)\n",
        "\n",
        "#진짜 헤더\n",
        "header = next(data)\n",
        "#print(header)\n",
        "\n",
        "for row in data:\n",
        "\n",
        "    #탭만 들어있는 관측치\n",
        "    if row[0] == '\\t':\n",
        "        break\n",
        "\n",
        "    #만약 결측치라면 999를 넣을 것!\n",
        "    if row[-2] =='':\n",
        "        row[-2] = 999\n",
        "\n",
        "    #문자열인 최저기온을 실수로 변환\n",
        "    row[-2] = float(row[-2])\n",
        "\n",
        "    #결과 출력(이젠 필요없음)\n",
        "    #print(row)\n",
        "\n",
        "    #만약 그날 최저기온이 저장해두었던 min_temp보다 낮다면!\n",
        "    if min_temp > row[-2]:\n",
        "        min_date = row[0][1:]\n",
        "        min_temp = row[-2]\n",
        "\n",
        "file.close()\n",
        "\n",
        "print('기상 관측 이래 청주의 최저기온이 가장 낮았던 날은 ' + min_date + '이고 이날은 무려 ' + str(min_temp) + '도 였습니다.')"
      ],
      "metadata": {
        "id": "3jo87O_acw6T"
      },
      "execution_count": null,
      "outputs": [],
      "id": "3jo87O_acw6T"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FULndhiBORRu"
      },
      "source": [
        "> **연습문제 6-1**. `temp_chungju.csv`를 사용하여 역대 가장 높은 최고기온이 언제 몇 도인지 식별하시오."
      ],
      "id": "FULndhiBORRu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5h3JMi-ORRv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('temp_chungju.csv', encoding = 'cp949', skiprows=7)\n",
        "\n",
        "highest = df.sort_values(by = '최고기온(℃)', ascending = False)\n",
        "highest.iloc[0][['날짜','최고기온(℃)']]"
      ],
      "id": "x5h3JMi-ORRv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82-hNaNgSeeK"
      },
      "source": [
        "> **연습문제 6-1**. `temp_chungju.csv`를 사용하여 역대 일교차가 가장 큰 날은 언제 몇 도인지 식별하시오."
      ],
      "id": "82-hNaNgSeeK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nHU71ldSeeM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('temp_chungju.csv', encoding = 'cp949', skiprows=7)\n",
        "\n",
        "df['range'] = df['최고기온(℃)'] - df['최저기온(℃)']\n",
        "highest = df.sort_values(by = 'range', ascending = False)\n",
        "highest.iloc[0][['날짜', 'range']]"
      ],
      "id": "2nHU71ldSeeM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 편리하지만 주의해야 하는 부분도 있다! 특히 문자열과 숫자의 구분에는 여전히 주의를 기울여야 한다. 가령 `\"121\", \"21\"`라는 데이터프레임이 있으면 이는 그대로 `\"121\", \"21\"`로 정렬된다. 변수의 타입(type)이 문자열로 설정되어 있기 때문이다(Why?). <b>숫자 기준</b>으로 정렬해야 $21$이 $121$보다 앞선다(Why?)."
      ],
      "metadata": {
        "id": "WE-TzbW2-6Wn"
      },
      "id": "WE-TzbW2-6Wn"
    },
    {
      "cell_type": "code",
      "source": [
        "ls = [\"121\", \"21\"]\n",
        "print(sorted(ls))\n",
        "\n",
        "ls = [121, 21]\n",
        "print(sorted(ls))"
      ],
      "metadata": {
        "id": "LaOv6pWTQb7l"
      },
      "id": "LaOv6pWTQb7l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 다행스럽게도 pandas의 발전에 힘입어 숫자라면 저절로 숫자로 인식해준다. 그렇지 않은 경우에도 물론 간단한 대안이 있다."
      ],
      "metadata": {
        "id": "vtv5Gad5ROPP"
      },
      "id": "vtv5Gad5ROPP"
    },
    {
      "cell_type": "code",
      "source": [
        "lowest = df.sort_values(by = '최저기온(℃)',\n",
        "                        ascending = True,\n",
        "                        key = pd.to_numeric)      #검색하건 생성형AI에 물어보면 금방이다!\n",
        "lowest"
      ],
      "metadata": {
        "id": "2pAxwFiG_EI_"
      },
      "execution_count": null,
      "outputs": [],
      "id": "2pAxwFiG_EI_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 정렬했기 때문에 새로운 결과물은 *인덱스* 수준에서 볼 때 뒤죽박죽 섞여있다. 필요하다면 `sort_index()`를 사용하여 인덱스에 따라 원상태로 복구할 수도 있다."
      ],
      "metadata": {
        "id": "8JOWB2mkD5Zs"
      },
      "id": "8JOWB2mkD5Zs"
    },
    {
      "cell_type": "code",
      "source": [
        "lowest = df.sort_values(by = '최저기온(℃)',\n",
        "                        ascending = True)\n",
        "lowest.sort_index()"
      ],
      "metadata": {
        "id": "wbMCtOfMD0xs"
      },
      "execution_count": null,
      "outputs": [],
      "id": "wbMCtOfMD0xs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60273307"
      },
      "source": [
        "## 7. 변수의 계산\n",
        "\n",
        "> 지금까지 데이터프레임의 내용을 변경하지는 않았다. 이제부터 새로운 변수를 만들고 변환해보자!\n",
        ">\n",
        "> 우선 데이터프레임 안에서 사칙연산을 수행할 수 있다. 가령 `cornhec`과 `soyhec`의 총합을 `hectare`로 합산하고 재배작물별 비율을 계산해보자."
      ],
      "id": "60273307"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "6953dd2b",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df['hectare'] = df['cornhec'] + df['soyhec']\n",
        "df['cornhec_p'] = df['cornhec'] / df['hectare']\n",
        "df"
      ],
      "id": "6953dd2b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <b>메서드(method)</b>를 사용하는 방식으로 같은 사칙연산을 할 수도 있다. 결과는 같지만, 나중에 이 방식이 더 유용하게 쓰일 때가 있다."
      ],
      "metadata": {
        "id": "T58HhN2hYfc8"
      },
      "id": "T58HhN2hYfc8"
    },
    {
      "cell_type": "code",
      "source": [
        "df['soyhec_p'] = df['soyhec'].div(df['hectare'])\n",
        "df"
      ],
      "metadata": {
        "id": "YaRgBPCEX-xj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YaRgBPCEX-xj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **연습문제 7-1**. `corn.csv`를 사용하여 콩의 픽셀이 전체 픽셀의 50% 이상 60% 미만인 카운티를 선별하시오."
      ],
      "metadata": {
        "id": "zqRfqx9uYres"
      },
      "id": "zqRfqx9uYres"
    },
    {
      "cell_type": "code",
      "source": [
        "df['soypix_p'] = df['soypix'] / (df['soypix'] + df['cornpix'])\n",
        "df[(df['soypix_p'] >= .5) & (df['soypix_p'] < .6)]"
      ],
      "metadata": {
        "id": "0P5jhuSTYuMV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "0P5jhuSTYuMV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **연습문제 7-2**. `corn.csv`를 사용하여 콩의 픽셀당 재배면적이 30% 미만의 카운티를 선별하시오."
      ],
      "metadata": {
        "id": "PobJs_Rlmp8_"
      },
      "id": "PobJs_Rlmp8_"
    },
    {
      "cell_type": "code",
      "source": [
        "df['soy_hp'] = df['soyhec'] / df['soypix']\n",
        "df[(df['soy_hp'] < .3)]"
      ],
      "metadata": {
        "id": "fwJgLOxfmp9G"
      },
      "execution_count": null,
      "outputs": [],
      "id": "fwJgLOxfmp9G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. 원소 단위 연산\n",
        "\n",
        "> **원소 단위(element-wise)** 연산이 그렇게 흔한 일은 아니기 때문에 상상하기가 조금 어려울 수 있다. 하지만 비교 목적에서는 얼마든지 있을 수 있는 연산이므로 익혀두어야 한다.\n",
        ">\n",
        "> 가령 모든 카운티가, 1번 카운티와 비교했을 때, 옥수수와 콩의 재배 면적이 어떻게 다른가를 살펴본다고 하자. 그러려면 (1) 먼저 1번 카운티만을 홀로 빼내어 수열로 만들고, (2) 이렇게 새로 만든 1번 카운티 수열에서 기존 `df`의 각 행(row)의 값을 빼야 한다(Why?).\n",
        "\n"
      ],
      "metadata": {
        "id": "dgKEkyKjdnbc"
      },
      "id": "dgKEkyKjdnbc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f25387",
      "metadata": {
        "id": "34f25387"
      },
      "outputs": [],
      "source": [
        "county1 = df.iloc[0]        #1번 카운티를 series로 만들기\n",
        "county1\n",
        "type(county1)               #series\n",
        "\n",
        "#모든 값들은 이제 1번 카운티와의 차이로 재정의된다!\n",
        "df - county1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0af6854b",
      "metadata": {
        "id": "0af6854b"
      },
      "source": [
        "> 원소 단위 뺄셈을 하기 위해 ``sub`` 매서드를 사용할 수도 있으며, 그 결과는 똑같다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "county1 = df.iloc[0]\n",
        "df.sub(county1)"
      ],
      "metadata": {
        "id": "szIMLDQvfoCE"
      },
      "id": "szIMLDQvfoCE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0b2241fc",
      "metadata": {
        "id": "0b2241fc"
      },
      "source": [
        "> 원소 단위로 사칙연산이 다 된다! 물론 매서드를 사용할 수도 있다. 하나씩 연습해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c647b6f",
      "metadata": {
        "scrolled": true,
        "id": "4c647b6f",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "county18 = df.iloc[18]\n",
        "\n",
        "#원소단위 뺄셈\n",
        "df.sub(county18)\n",
        "df - county18\n",
        "\n",
        "#원소단위 덧셈\n",
        "df.add(county18)\n",
        "df + county18\n",
        "\n",
        "#원소단위 곱셈\n",
        "df.mul(county18)\n",
        "df * county18\n",
        "\n",
        "#원소단위 나눗셈\n",
        "df.div(county18)\n",
        "df / county18"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b195756c",
      "metadata": {
        "id": "b195756c"
      },
      "source": [
        "> 지금까지 작업한 데이터프레임을 새로운 csv 파일로 저장할 수도 있다. 폴더 아이콘을 눌러 제대로 저장되는지 살펴보자. (앞서 제대로 연동했다면) 여러분의 구글 드라이브에 직접 저장할 수도 있다(파일 이름 위에서 우클릭하면 폴더 이름을 복사해둘 수 있으니 참고하자)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab3b286",
      "metadata": {
        "id": "9ab3b286"
      },
      "outputs": [],
      "source": [
        "df.to_csv('corn_new.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **연습문제 8-1**. 27번째 관측치의 `soyhec`보다 큰 면적을 가진 카운티만 선별하시오."
      ],
      "metadata": {
        "id": "e5F111MasOgo"
      },
      "id": "e5F111MasOgo"
    },
    {
      "cell_type": "code",
      "source": [
        "twentyseven = df.iloc[27]\n",
        "print(twentyseven['soyhec'])       #132.33\n",
        "df[df['soyhec'] > twentyseven['soyhec']]"
      ],
      "metadata": {
        "id": "lLqB0juKsOgq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "lLqB0juKsOgq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **연습문제 8-2**. `corn.csv`의 2번째 관측치에 비하여 다른 관측치가 각각 몇 퍼센트인지 구하시오.\n",
        ">\n",
        "> ---\n",
        "> 힌트: 가령 1번째 관측치의 `cornhec` 값은 165.76이다. 2번째 관측치의 `cornhec`값은 76.08이다. 그러므로 여러분은 1번째 관측치를 $(165.76 - 76.08) * 100 \\approx 217.87$로 바꾸어 표시해야 한다."
      ],
      "metadata": {
        "id": "dsOa8k7wpZ-E"
      },
      "id": "dsOa8k7wpZ-E"
    },
    {
      "cell_type": "code",
      "source": [
        "second = df.iloc[2]\n",
        "df / second * 100"
      ],
      "metadata": {
        "id": "nCY1s5nupZ-F"
      },
      "execution_count": null,
      "outputs": [],
      "id": "nCY1s5nupZ-F"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}